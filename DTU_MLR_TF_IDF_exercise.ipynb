{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sneharc16/DTU-MLR-Assignments-Deep-Learning/blob/main/DTU_MLR_TF_IDF_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVrcHNZpQLUz"
      },
      "source": [
        "### **TF-IDF: Exercises**\n",
        "\n",
        "- Humans ðŸ‘¦ show different emotions/feelings based on the situations and communicate them through facial expressions or in form of words.\n",
        "\n",
        "- In Social Media like Twitter and Instagram, many people express their views through comments about a particular event/scenario and these comments may address the feelings like sadness, happiness, joy, sarcasm, fear, and many other.\n",
        "\n",
        "- For a given comment/text, we are going to use classical NLP techniques and classify under which emotion that particular comment belongs!\n",
        "\n",
        "- We are going to use techniques like Bag of grams, n-grams, TF-IDF, etc. for text representation and apply different classification algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU5KDovsV9ez"
      },
      "source": [
        "### **About Data: Emotion Detection**\n",
        "\n",
        "Credits: https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp\n",
        "\n",
        "\n",
        "- This data consists of two columns.\n",
        "        - Comment\n",
        "        - Emotion\n",
        "- Comment are the statements or messages regarding to a particular event/situation.\n",
        "\n",
        "- Emotion feature tells whether the given comment is fear ðŸ˜¨, Anger ðŸ˜¡, Joy ðŸ˜‚.\n",
        "\n",
        "- As there are only 3 classes, this problem comes under the **Multi-Class Classification.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d praveengovi/emotions-dataset-for-nlp\n",
        "\n",
        "!unzip emotions-dataset-for-nlp.zip\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMWFgMKQAXL3",
        "outputId": "dbfd42cf-c3cb-4187-80f1-f01faef814ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp\n",
            "License(s): CC-BY-SA-4.0\n",
            "Downloading emotions-dataset-for-nlp.zip to /content\n",
            "  0% 0.00/721k [00:00<?, ?B/s]\n",
            "100% 721k/721k [00:00<00:00, 105MB/s]\n",
            "Archive:  emotions-dataset-for-nlp.zip\n",
            "  inflating: test.txt                \n",
            "  inflating: train.txt               \n",
            "  inflating: val.txt                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv train.txt train.csv\n",
        "!mv val.txt val.csv\n",
        "!mv test.txt test.csv"
      ],
      "metadata": {
        "id": "gUme0jMZA_gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ML2s0KWVXmv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a90d8ceb-de9a-409f-99b4-9ab67eee231f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16000, 2)\n",
            "                                            Sentence  Emotion\n",
            "0                            i didnt feel humiliated  sadness\n",
            "1  i can go from feeling so hopeless to so damned...  sadness\n",
            "2   im grabbing a minute to post i feel greedy wrong    anger\n",
            "3  i am ever feeling nostalgic about the fireplac...     love\n",
            "4                               i am feeling grouchy    anger\n"
          ]
        }
      ],
      "source": [
        "#import pandas library\n",
        "import pandas as pd\n",
        "\n",
        "#read the dataset with name \"Emotion_classify_Data.csv\" and store it in a variable df\n",
        "train = pd.read_csv(\"train.csv\", sep = \";\", names=['Sentence', 'Emotion'])\n",
        "val = pd.read_csv(\"val.csv\", sep = \";\")\n",
        "test = pd.read_csv(\"test.csv\", sep = \";\")\n",
        "\n",
        "#print the shape of dataframe\n",
        "print(train.shape)\n",
        "\n",
        "#print top 5 rows\n",
        "print(train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joLuZmFpT-fY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2888431b-d81e-4850-972f-8615067da245"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Emotion\n",
              "joy         5362\n",
              "sadness     4666\n",
              "anger       2159\n",
              "fear        1937\n",
              "love        1304\n",
              "surprise     572\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#check the distribution of Emotion\n",
        "train[\"Emotion\"].value_counts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPxiqT_TT-hx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c878ed3b-f8ed-4827-94da-8afd4838e061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Sentence  Emotion  Emotion_num\n",
            "0                            i didnt feel humiliated  sadness            3\n",
            "1  i can go from feeling so hopeless to so damned...  sadness            3\n",
            "2   im grabbing a minute to post i feel greedy wrong    anger            2\n",
            "3  i am ever feeling nostalgic about the fireplac...     love            4\n",
            "4                               i am feeling grouchy    anger            2\n"
          ]
        }
      ],
      "source": [
        "#Add the new column \"Emotion_num\" which gives a unique number to each of these Emotions\n",
        "#joy --> 0, fear --> 1, anger --> 2\n",
        "emotion_num_list = []\n",
        "for i in train[\"Emotion\"]:\n",
        "    if i == \"joy\":\n",
        "        emotion_num_list.append(0)\n",
        "    elif i == \"fear\":\n",
        "        emotion_num_list.append(1)\n",
        "    elif i == \"anger\":\n",
        "        emotion_num_list.append(2)\n",
        "    elif i == \"sadness\":\n",
        "        emotion_num_list.append(3)\n",
        "    elif i == \"love\":\n",
        "        emotion_num_list.append(4)\n",
        "    elif i == \"surprise\":\n",
        "        emotion_num_list.append(5)\n",
        "\n",
        "# Add the new column \"Emotion_num\" to the DataFrame\n",
        "train[\"Emotion_num\"] = emotion_num_list\n",
        "\n",
        "#checking the results by printing top 5 rows\n",
        "print (train.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE-c0zbDXTEm"
      },
      "source": [
        "### **Modelling without Pre-processing Text data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjJqi7UBT-nr"
      },
      "outputs": [],
      "source": [
        "#import train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Do the 'train-test' splitting with test size of 20%\n",
        "X_train, X_test = train_test_split(train, test_size=0.2, random_state=2022, stratify=train[\"Emotion\"])\n",
        "\n",
        "#Note: Give Random state 2022 and also do the stratify sampling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lAD0iqGcdCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f58f8a-5cee-4155-bf16-56418b72bd52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12800, 3)\n",
            "(3200, 3)\n"
          ]
        }
      ],
      "source": [
        "#print the shapes of X_train and X_test\n",
        "print (X_train.shape)\n",
        "print (X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6h8ZZLxZd79"
      },
      "source": [
        "\n",
        "**Attempt 1** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "\n",
        "**Note:**\n",
        "- using CountVectorizer with only trigrams.\n",
        "- use **RandomForest** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGg2iXv6g40l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "3a13d4f3-4cb3-425a-a647-2d83089b9b3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', CountVectorizer(ngram_range=(3, 3))),\n",
              "                ('classifier', RandomForestClassifier())])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer(ngram_range=(3, 3))),\n",
              "                (&#x27;classifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer(ngram_range=(3, 3))),\n",
              "                (&#x27;classifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(3, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#import CountVectorizer, RandomForest, pipeline, classification_report from sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#1. create a pipeline object\n",
        "pipe_RFC = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(ngram_range=(3, 3))),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "pipe_RFC.fit(X_train[\"Sentence\"], X_train[\"Emotion\"])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. get the predictions for X_test and store it in y_pred\n",
        "y_pred = pipe_RFC.predict(X_test[\"Sentence\"])\n",
        "\n",
        "\n",
        "#4. print the classfication report\n",
        "print(classification_report(X_test[\"Emotion\"], y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftElFed-NLkp",
        "outputId": "fbe25384-2f13-4804-9122-8da9543c13a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.53      0.18      0.26       432\n",
            "        fear       0.54      0.28      0.37       387\n",
            "         joy       0.41      0.87      0.56      1072\n",
            "        love       0.62      0.11      0.19       261\n",
            "     sadness       0.58      0.32      0.41       933\n",
            "    surprise       0.54      0.13      0.21       115\n",
            "\n",
            "    accuracy                           0.46      3200\n",
            "   macro avg       0.54      0.31      0.33      3200\n",
            "weighted avg       0.51      0.46      0.41      3200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I08-kc_JYCNL"
      },
      "source": [
        "\n",
        "**Attempt 2** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "\n",
        "**Note:**\n",
        "- using CountVectorizer with both unigram and bigrams.\n",
        "- use **Multinomial Naive Bayes** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zetSmBrXmjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c68626b5-cd47-400b-e5f6-d3b917a04302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.54      0.18      0.26       432\n",
            "        fear       0.57      0.26      0.36       387\n",
            "         joy       0.41      0.88      0.56      1072\n",
            "        love       0.63      0.11      0.19       261\n",
            "     sadness       0.58      0.32      0.41       933\n",
            "    surprise       0.50      0.13      0.21       115\n",
            "\n",
            "    accuracy                           0.46      3200\n",
            "   macro avg       0.54      0.31      0.33      3200\n",
            "weighted avg       0.52      0.46      0.41      3200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#import MultinomialNB from sklearn\n",
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#1. create a pipeline object\n",
        "pipe_multi = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
        "    ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "\n",
        "pipe_multi.fit(X_train[\"Sentence\"], X_train[\"Emotion\"])\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "pipe_multi.predict(X_test[\"Sentence\"])\n",
        "\n",
        "#4. print the classfication report\n",
        "print(classification_report(X_test[\"Emotion\"], y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wde4r_-YwU-"
      },
      "source": [
        "\n",
        "**Attempt 3** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "\n",
        "**Note:**\n",
        "- using CountVectorizer with both unigram and Bigrams.\n",
        "- use **RandomForest** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0dG2tc0X7SK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34bead97-33f4-435b-93f7-7101a3df694c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.53      0.18      0.26       432\n",
            "        fear       0.54      0.28      0.37       387\n",
            "         joy       0.41      0.87      0.56      1072\n",
            "        love       0.62      0.11      0.19       261\n",
            "     sadness       0.58      0.32      0.41       933\n",
            "    surprise       0.54      0.13      0.21       115\n",
            "\n",
            "    accuracy                           0.46      3200\n",
            "   macro avg       0.54      0.31      0.33      3200\n",
            "weighted avg       0.51      0.46      0.41      3200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#1. create a pipeline object\n",
        "pipe_uni_bi = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "pipe_uni_bi.fit(X_train[\"Sentence\"], X_train[\"Emotion\"])\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "pipe_uni_bi.predict(X_test[\"Sentence\"])\n",
        "\n",
        "\n",
        "#4. print the classfication report\n",
        "print(classification_report(X_test[\"Emotion\"], y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmrXmL_3Z2y6"
      },
      "source": [
        "\n",
        "**Attempt 4** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "\n",
        "**Note:**\n",
        "- using **TF-IDF vectorizer** for Pre-processing the text.\n",
        "- use **RandomForest** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> data: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
      ],
      "metadata": {
        "id": "HLMEHD2Dj1Hp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IMDB title classifier begins"
      ],
      "metadata": {
        "id": "3OmRGy2-Z-Ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
        "\n",
        "!unzip imdb-dataset-of-50k-movie-reviews.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s97Eh5TJaB2_",
        "outputId": "77c9bfb6-509c-47bf-e7b6-5ad7ed4732fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
            "License(s): other\n",
            "imdb-dataset-of-50k-movie-reviews.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  imdb-dataset-of-50k-movie-reviews.zip\n",
            "replace IMDB Dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "imdb = pd.read_csv(\"/content/IMDB Dataset.csv\")\n",
        "\n",
        "X_train, X_test = train_test_split(imdb, test_size=0.05, random_state=2022, stratify=imdb[\"sentiment\"])"
      ],
      "metadata": {
        "id": "82CafNbJaN5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.head())\n",
        "X_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1jzXfGva6Br",
        "outputId": "4210b41b-d201-45d0-db09-bceac2ec1fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  review sentiment\n",
            "38751  'Panic in the Streets (1950)' owes more to Bri...  positive\n",
            "18095  I got to see an early preview of this movie an...  negative\n",
            "26076  The performances were superb, the costumes del...  positive\n",
            "20799  Wesley Snipes is perfectly cast as Blade, a ha...  positive\n",
            "6663   Ernst Lubitsch gave us wonderful films like De...  positive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import TfidfVectorizer from sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "## generate cosine similarity\n",
        "import math\n",
        "\n",
        "def cosine_similarity(vector1, vector2):\n",
        "    \"\"\"\n",
        "    Calculate the cosine similarity between two vectors.\n",
        "\n",
        "    Args:\n",
        "        vector1 (list): The first vector.\n",
        "        vector2 (list): The second vector.\n",
        "\n",
        "    Returns:\n",
        "        float: The cosine similarity between the two vectors.\n",
        "    \"\"\"\n",
        "\n",
        "    # IMPLEMENT\n",
        "\n",
        "    dot_product = np.dot(vector1, vector2)\n",
        "    norm1 = np.linalg.norm(vector1)\n",
        "    norm2 = np.linalg.norm(vector2)\n",
        "    cosine_sim = dot_product / (norm1 * norm2)\n",
        "\n",
        "    return cosine_sim\n",
        "\n",
        "## implement get_recomendation()\n",
        "\n",
        "def get_recommendations(title, cosine_sim, indices):\n",
        "    # Get index of movie that matches title\n",
        "    idx = indices[title]\n",
        "\n",
        "    # Sort the movies based on the similarity scores\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the scores for 10 most similar movies\n",
        "    sim_scores = sim_scores[1:11]\n",
        "\n",
        "    # Get the movie indices\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    # Return the top 10 most similar movies\n",
        "    return imdb['review'][movie_indices]"
      ],
      "metadata": {
        "id": "K5yr_Jj9i8dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Try to implement cosine similarity from scratch"
      ],
      "metadata": {
        "id": "CY0-hbATlD1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djsDsThaaCSO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "90f959a7-7875-44e3-92a7-fed0171b9147"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
              "                ('classifier', RandomForestClassifier())])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
              "                (&#x27;classifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
              "                (&#x27;classifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#1. create a pipeline object\n",
        "pipe_imdb = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "pipe_imdb.fit(X_train[\"review\"], X_train[\"sentiment\"])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. get the predictions for X_test and store it in y_pred\n",
        "\n",
        "y_pred_imdb = pipe_imdb.predict(X_test[\"review\"])\n",
        "\n",
        "#4. print the classfication\n",
        "\n",
        "print (classification_report(X_test[\"sentiment\"], y_pred_imdb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjZognpYb7MC",
        "outputId": "f4a298c0-da7f-443c-f760-17c74c8b2305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.80      0.81      0.80     23750\n",
            "    positive       0.81      0.80      0.80     23750\n",
            "\n",
            "    accuracy                           0.80     47500\n",
            "   macro avg       0.80      0.80      0.80     47500\n",
            "weighted avg       0.80      0.80      0.80     47500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ACq6pDkZ4sA"
      },
      "source": [
        "<h3>Use text pre-processing to remove stop words, punctuations and apply lemmatization </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj_xYgthX7UF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c79bb922-0d43-4e2b-f643-9cc59f765a69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# load english language model and create nlp object from it\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "#use this utility function to get the preprocessed text data\n",
        "def preprocess(text):\n",
        "    # remove stop words and lemmatize the text\n",
        "    doc = nlp(text)\n",
        "    filtered_tokens = []\n",
        "    for token in doc:\n",
        "        if token.is_stop or token.is_punct:\n",
        "            continue\n",
        "        filtered_tokens.append(token.lemma_)\n",
        "\n",
        "    return \" \".join(filtered_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqW1i19wX7Xq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9fa13b-0a62-4254-bb0f-d1533ed8eeb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  review sentiment  \\\n",
            "38751  'Panic in the Streets (1950)' owes more to Bri...  positive   \n",
            "18095  I got to see an early preview of this movie an...  negative   \n",
            "26076  The performances were superb, the costumes del...  positive   \n",
            "20799  Wesley Snipes is perfectly cast as Blade, a ha...  positive   \n",
            "6663   Ernst Lubitsch gave us wonderful films like De...  positive   \n",
            "\n",
            "                                    preprocessed_comment  \n",
            "38751  Panic Streets 1950 owe british noir american c...  \n",
            "18095  get early preview movie hope time edit way imp...  \n",
            "26076  performance superb costume deliver unique feel...  \n",
            "20799  Wesley Snipes perfectly cast Blade half human ...  \n",
            "6663   Ernst Lubitsch give wonderful film like Design...  \n"
          ]
        }
      ],
      "source": [
        "# create a new column \"preprocessed_comment\" and use the utility function above to get the clean data\n",
        "# this will take some time, please be patient\n",
        "\n",
        "X_train[\"preprocessed_comment\"] = X_train[\"review\"].apply(preprocess)\n",
        "\n",
        "print(X_train.head())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_preprocessed = X_train.copy()\n",
        "\n",
        "X_train_preprocessed.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oKNCtj48UMDC",
        "outputId": "580bbe94-825d-4aad-c6c9-7cbc995d8534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment  \\\n",
              "38751  'Panic in the Streets (1950)' owes more to Bri...  positive   \n",
              "18095  I got to see an early preview of this movie an...  negative   \n",
              "26076  The performances were superb, the costumes del...  positive   \n",
              "20799  Wesley Snipes is perfectly cast as Blade, a ha...  positive   \n",
              "6663   Ernst Lubitsch gave us wonderful films like De...  positive   \n",
              "\n",
              "                                    preprocessed_comment  \n",
              "38751  Panic Streets 1950 owe british noir american c...  \n",
              "18095  get early preview movie hope time edit way imp...  \n",
              "26076  performance superb costume deliver unique feel...  \n",
              "20799  Wesley Snipes perfectly cast Blade half human ...  \n",
              "6663   Ernst Lubitsch give wonderful film like Design...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9591cd2a-1427-40aa-bbd0-e08bef88bd34\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>preprocessed_comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>38751</th>\n",
              "      <td>'Panic in the Streets (1950)' owes more to Bri...</td>\n",
              "      <td>positive</td>\n",
              "      <td>Panic Streets 1950 owe british noir american c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18095</th>\n",
              "      <td>I got to see an early preview of this movie an...</td>\n",
              "      <td>negative</td>\n",
              "      <td>get early preview movie hope time edit way imp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26076</th>\n",
              "      <td>The performances were superb, the costumes del...</td>\n",
              "      <td>positive</td>\n",
              "      <td>performance superb costume deliver unique feel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20799</th>\n",
              "      <td>Wesley Snipes is perfectly cast as Blade, a ha...</td>\n",
              "      <td>positive</td>\n",
              "      <td>Wesley Snipes perfectly cast Blade half human ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6663</th>\n",
              "      <td>Ernst Lubitsch gave us wonderful films like De...</td>\n",
              "      <td>positive</td>\n",
              "      <td>Ernst Lubitsch give wonderful film like Design...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9591cd2a-1427-40aa-bbd0-e08bef88bd34')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9591cd2a-1427-40aa-bbd0-e08bef88bd34 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9591cd2a-1427-40aa-bbd0-e08bef88bd34');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4e1b5ead-022f-4c87-8c30-faefa4d4ea34\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4e1b5ead-022f-4c87-8c30-faefa4d4ea34')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4e1b5ead-022f-4c87-8c30-faefa4d4ea34 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train_preprocessed",
              "summary": "{\n  \"name\": \"X_train_preprocessed\",\n  \"rows\": 2500,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2498,\n        \"samples\": [\n          \"I've Seen The Beginning Of The Muppet Movie, But Just The Half. Because I Only Watched It At Mrs Kelly's Friend's House. The Songs Were The Best And The Muppets Were So Hilarious. They Learn That If They Believe In The End Of The Rainbow, Anyone Can Make It, No Matter How Small, No Matter How Green(Which Was Included In The Trailer).<br /><br />Kermit Is My Favorite Protagonist(Which Means It Describes The Main Character) And So Are The Other Muppets. Mel Brooks Was Amazing When He Played Professor Max Krassman. The Scene Where Miss Piggy Saves Kermit By Doing Kung Fu On Those Guys. It Was So Cool.<br /><br />The Muppet Movie Is The Best Jim Henson Film With The Most Hilarious Characters And People Will Cherish For His Successful Film.\",\n          \"Hubie -- like Stanely the troll from Bluth's A Troll in Central Park -- lacks the spark of personality to be the main character that carries an entire movie. We're supposed to like him because he's nice, but that's about all he is.<br /><br />His character design is unappealing. The top of his head is a sort of dome that is narrower than the pudgy bottom half of his head.<br /><br />And penguins should not have teeth. I know that Iago the parrot in Aladdin had teeth, but maybe that worked because it made him look more like his voice actor, Gilbert Gottfried. Hubie, with his weenie little voice (provided by Martin Short), looks funny with that big set of chompers in his beak.<br /><br />Tim Curry, who is usually delightful at being evil, does some sort of dippy surfer dude accent as the villain (might have been a good voice for a comic relief accomplice, not the supposedly menacing main villain).<br /><br />The entire plot revolves around the hero and villain's love for female penguin Marina, who is just as dull as both of her suitors.<br /><br />Worst of all is the pacing. We keep cutting back to the villain to watch him threaten Marina some more - this time in dialogue, this time in song...<br /><br />Barry Manilow may be a great songwriter, but in animated films like this and Thumbelina, his songs feel limp and listless - especially the ballads. The only song I liked was the 1930's-ish \\\"Good Ship Misery\\\" song.<br /><br />I read that the distributor made some cuts in this film against the filmmaker's wishes, and that could have caused some of the problems - though I suspect the real problem is that they didn't cut the rest of it ;).\",\n          \"I'm not sure why Spike Lee made this train wreck of a movie and conned poor Stevie Wonder into eternally pairing his beautiful music with this theatrical mess. I also resent the way he uses profanity as a part of the normal prose of professional Blacks. The abuse of his hold on ethnic movie goers is a shame. Scenes which seem to be contrived out the blue and have nothing to do with the theme or sub themes, play as if some college kid wrote this. I especially detest the ludicrous scene where the two leads are playfully sparring for no reason at all and the cops come and rough up Snipes. The overacting of the leads makes one feel as if Spike has no respect for his viewers or he has no clue what a movie is all about. The final scene appears to be thrown in to justify the use of a sledge hammer to tack a point in. This movie also supports the myth that all people of culture use the F-word in casual conversation. I am hoping he will realize that the rest of his movies are in the same pool as this one where he is not growing as a film maker. I think his union with Scorcesee in Clockers was a wise move. He should stick to making documentaries like the Four Little Colored Girls. Shock movies do not an Oscar make.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preprocessed_comment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2498,\n        \"samples\": [\n          \"see beginning Muppet Movie half watch Mrs Kelly Friend House Songs good Muppets hilarious learn believe end Rainbow matter small matter green(which include trailer).<br /><br />Kermit favorite protagonist(which mean describe Main Character Muppets Mel Brooks Amazing play Professor Max Krassman Scene Miss Piggy Saves Kermit Kung Fu Guys Cool.<br /><br />The Muppet Movie good Jim Henson Film Hilarious Characters People cherish Successful Film\",\n          \"Hubie like stanely troll Bluth Troll Central Park lack spark personality main character carry entire movie suppose like nice is.<br /><br />His character design unappeale head sort dome narrow pudgy half head.<br /><br />And penguin tooth know Iago parrot Aladdin tooth maybe work look like voice actor Gilbert Gottfried Hubie weenie little voice provide Martin Short look funny big set chomper beak.<br /><br />Tim Curry usually delightful evil sort dippy surfer dude accent villain good voice comic relief accomplice supposedly menacing main villain).<br /><br />The entire plot revolve hero villain love female penguin Marina dull suitors.<br /><br />worst pacing cut villain watch threaten Marina time dialogue time song <br /><br />barry Manilow great songwriter animate film like Thumbelina song feel limp listless especially ballad song like 1930' ish Good ship Misery song.<br /><br />i read distributor cut film filmmaker wish cause problem suspect real problem cut rest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[\"preprocessed_comment\"] = X_test[\"review\"].apply(preprocess)\n",
        "print(X_test.head())\n",
        "X_test_preprocessed = X_test.copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luX4lkRsQCzw",
        "outputId": "d0c345ee-60f6-49a1-a00b-69dc7c3550b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  review sentiment  \\\n",
            "23059  This movie was in a sci-fi 50-pack a friend of...  negative   \n",
            "6765   I bought Jack-O a number of months ago at a Bl...  negative   \n",
            "21325  While it contains facts that are not widely re...  negative   \n",
            "32551  I have never seen so much talent and money use...  negative   \n",
            "7937   I simply cannot believe the number of people c...  negative   \n",
            "\n",
            "                                    preprocessed_comment  \n",
            "23059  movie sci fi 50 pack friend get Christmas simi...  \n",
            "6765   buy Jack o number month ago Blockbuster video ...  \n",
            "21325  contain fact widely report exactly truth take ...  \n",
            "32551  see talent money produce bad entire life state...  \n",
            "7937   simply believe number people compare favourabl...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test_preprocessed.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CgWpCltUBt5",
        "outputId": "ed33aed4-3a4a-4525-d339-90ea946251dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  review sentiment  \\\n",
            "23059  This movie was in a sci-fi 50-pack a friend of...  negative   \n",
            "6765   I bought Jack-O a number of months ago at a Bl...  negative   \n",
            "21325  While it contains facts that are not widely re...  negative   \n",
            "32551  I have never seen so much talent and money use...  negative   \n",
            "7937   I simply cannot believe the number of people c...  negative   \n",
            "\n",
            "                                    preprocessed_comment  \n",
            "23059  movie sci fi 50 pack friend get Christmas simi...  \n",
            "6765   buy Jack o number month ago Blockbuster video ...  \n",
            "21325  contain fact widely report exactly truth take ...  \n",
            "32551  see talent money produce bad entire life state...  \n",
            "7937   simply believe number people compare favourabl...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q24oRlMcai9l"
      },
      "source": [
        "**Build a model with pre processed text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahdd2mgxX7dM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93ecc058-c7d0-47dd-c340-49ce1ccc24c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18396    heart Darkness Movie Review Joseph Conrad Hear...\n",
              "33553    like Summerslam look arena curtain look overal...\n",
              "15662    actually pretty good like show tv good episode...\n",
              "7432     energetic entertain minute film > see long tim...\n",
              "23768    title sum heap crap take hint see Fred olen Ra...\n",
              "Name: preprocessed_comment, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
        "#Note: Use the preprocessed_Comment\n",
        "\n",
        "\n",
        "# Assuming X_train and X_test are your preprocessed features\n",
        "X_train_nlp, X_test_nlp, y_train_nlp, y_test_nlp = train_test_split(\n",
        "    X_train_preprocessed[\"preprocessed_comment\"],\n",
        "    X_train_preprocessed[\"sentiment\"],\n",
        "    test_size=0.2,\n",
        "    random_state=2022,\n",
        "    stratify=X_train_preprocessed[\"sentiment\"]\n",
        ")\n",
        "# Create DataFrames for X_train_nlp and X_test_nlp (if needed)\n",
        "#no need\n",
        "\n",
        "# Display the first few rows of X_train_nlp\n",
        "#done later\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqonfpeYasOE"
      },
      "source": [
        "**Let's check the scores with our best model till now**\n",
        "- Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1wYgFs3auLQ"
      },
      "source": [
        "\n",
        "**Attempt1** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "\n",
        "**Note:**\n",
        "- using CountVectorizer with both unigrams and bigrams.\n",
        "- use **RandomForest** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Khtu32z1XmmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62101797-f65f-4711-afda-412b4ab02fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.83      0.76      0.79      1250\n",
            "    positive       0.78      0.85      0.81      1250\n",
            "\n",
            "    accuracy                           0.80      2500\n",
            "   macro avg       0.81      0.80      0.80      2500\n",
            "weighted avg       0.81      0.80      0.80      2500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "#1. create a pipeline object\n",
        "pipe_nlp = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "pipe_nlp.fit(X_train_preprocessed[\"preprocessed_comment\"], X_train_preprocessed[\"sentiment\"])\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "y_pred_nlp = pipe_nlp.predict(X_test_preprocessed[\"preprocessed_comment\"])\n",
        "\n",
        "\n",
        "#4. print the classfication report\n",
        "print(classification_report(X_test_preprocessed[\"sentiment\"], y_pred_nlp))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9GZPaQbbJbx"
      },
      "source": [
        "\n",
        "**Attempt 2** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the data.\n",
        "\n",
        "**Note:**\n",
        "- using **TF-IDF vectorizer** for pre-processing the text.\n",
        "- use **RandomForest** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2y1Cy4Bauxu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e891288b-c1d9-40f0-8d34-a8a72885fff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.80      0.81      0.80      1250\n",
            "    positive       0.81      0.80      0.80      1250\n",
            "\n",
            "    accuracy                           0.80      2500\n",
            "   macro avg       0.80      0.80      0.80      2500\n",
            "weighted avg       0.80      0.80      0.80      2500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#1. create a pipeline object\n",
        "pipe_tf_idf_nlp = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "pipe_tf_idf_nlp.fit(X_train_preprocessed[\"preprocessed_comment\"], X_train_preprocessed[\"sentiment\"])\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "y_pred_tf_idf_nlp = pipe_tf_idf_nlp.predict(X_test_preprocessed[\"preprocessed_comment\"])\n",
        "\n",
        "\n",
        "#4. print the classfication report\n",
        "print (classification_report(X_test_preprocessed[\"sentiment\"], y_pred_tf_idf_nlp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eYaKDLaaxbM"
      },
      "source": [
        "## **Please write down Final Observations**\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}